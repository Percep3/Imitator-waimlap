{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56291f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37dea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "from src.mslm.models import Imitator, PositionalEncoding\n",
    "from src.mslm.dataloader import KeypointDataset, SignDataLoader, collate_fn\n",
    "from src.mslm.utils.llm_tools import Tools\n",
    "\n",
    "from src.mslm.inference import MultimodalSignLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59d2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParameters = {\n",
    "    \"input_size\": 543*2,\n",
    "    \"output_size\": 3072,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"epochs\": 1000,\n",
    "    \"logIntervals\": 20,\n",
    "    \"checkpointIntervals\": 40,\n",
    "    \"batchSize\": 32,\n",
    "    \"frameClips\": 15 * 35,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"validation_ratio\": 0.2\n",
    "}\n",
    "# model = Imitator(input_size=modelParameters[\"input_size\"], T_size=modelParameters[\"frameClips\"], output_size=modelParameters[\"output_size\"]).to(modelParameters[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!ls ../../outputs/checkpoints/41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([Imitator, PositionalEncoding, FastLanguageModel, Tools])\n",
    "model_checkpoint_path = \"../../outputs/checkpoints/finetuning/41/1/1/5/checkpoint.pth\"\n",
    "model_checkpoint_path = \"/home/giorgio6846/Code/Sign-AI/Sign-Multimodal-Language-Model/outputs/model/checkpoints/33/1/15/model.pt\"\n",
    "state_dict = torch.load(model_checkpoint_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973395ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = os.path.join(os.path.dirname(os.getcwd()), os.pardir, \"data\", \"dataset2\")\n",
    "h5File = os.path.join(DataPath, \"keypoints.h5\")\n",
    "csvFile = os.path.join(DataPath, \"meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798b57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 * 2\n",
    "load_in_4bit = True\n",
    "dtype=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493a9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 15.576 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "llama_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e445d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = llama_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf14b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 15.576 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "LOG = False\n",
    "tools = Tools()\n",
    "keypointReader = KeypointDataset(h5Path=h5File, labelsCSV=csvFile, max_seq_len=modelParameters[\"frameClips\"])[0]\n",
    "dataset = SignDataLoader(tokenizer, [keypointReader], modelParameters[\"device\"])\n",
    "test_dataloader = DataLoader(dataset, batch_size=modelParameters[\"batchSize\"], shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff01e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = state_dict.to(modelParameters[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['_orig_mod.stgcn.blocks.0.spatial_conv.weight', '_orig_mod.stgcn.blocks.0.spatial_conv.bias', '_orig_mod.stgcn.blocks.0.temp_conv.weight', '_orig_mod.stgcn.blocks.0.temp_conv.bias', '_orig_mod.stgcn.blocks.0.norm.weight', '_orig_mod.stgcn.blocks.0.norm.bias', '_orig_mod.stgcn.blocks.0.norm.running_mean', '_orig_mod.stgcn.blocks.0.norm.running_var', '_orig_mod.stgcn.blocks.0.norm.num_batches_tracked', '_orig_mod.stgcn.blocks.1.spatial_conv.weight', '_orig_mod.stgcn.blocks.1.spatial_conv.bias', '_orig_mod.stgcn.blocks.1.temp_conv.weight', '_orig_mod.stgcn.blocks.1.temp_conv.bias', '_orig_mod.stgcn.blocks.1.norm.weight', '_orig_mod.stgcn.blocks.1.norm.bias', '_orig_mod.stgcn.blocks.1.norm.running_mean', '_orig_mod.stgcn.blocks.1.norm.running_var', '_orig_mod.stgcn.blocks.1.norm.num_batches_tracked', '_orig_mod.temporal_adjuster.0.weight', '_orig_mod.temporal_adjuster.0.bias', '_orig_mod.linear_out.weight', '_orig_mod.linear_out.bias'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace('_orig_mod.', '')  # elimina el prefijo\n",
    "    new_state_dict[new_key] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9aee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with state dict\n",
    "model = Imitator(input_size=modelParameters[\"input_size\"], T_size=modelParameters[\"frameClips\"], output_size=modelParameters[\"output_size\"]).to(modelParameters[\"device\"])\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f62c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerrar las canillas durante el cepillado de dientes, de lavarse las manos, de la cara, de afeitarse, de lavar los platos, pelar papas, en lugar de dejar correr el agua.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypointReader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80811e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128000,  24913,    277,   5252,    649,  34344,  30331,    658,  63190,\n",
       "           484,   2172,    409,    294,  27335,     11,    409,  30583,   2648,\n",
       "          5252,  97349,     11,    409,   1208,  48034,     11,    409,    264,\n",
       "         62221,   2648,     11,    409,  30583,    277,   2537,    628,  14357,\n",
       "            11,  12077,    277,  26365,    300,     11,    665,  35000,    409,\n",
       "         81499,   1867,  38149,    658,  56562,     13, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd02f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e46d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imitator(\n",
       "  (stgcn): STGCN(\n",
       "    (blocks): ModuleList(\n",
       "      (0): SimpleSTGCNBlock(\n",
       "        (spatial_conv): Conv2d(1086, 3072, kernel_size=(1, 25), stride=(1, 1), padding=(0, 12))\n",
       "        (temp_conv): Conv2d(3072, 3072, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
       "        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): SimpleSTGCNBlock(\n",
       "        (spatial_conv): Conv2d(3072, 3072, kernel_size=(1, 25), stride=(1, 1), padding=(0, 12))\n",
       "        (temp_conv): Conv2d(3072, 3072, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
       "        (norm): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_adjuster): Sequential(\n",
       "    (0): Linear(in_features=525, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (linear_out): Linear(in_features=3072, out_features=3072, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ea038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-30464., device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "llama_model.eval()\n",
    "mslm = MultimodalSignLM(llama_model, tokenizer, \"cuda\")\n",
    "\n",
    "text = \"Enumera los pasos descritos:\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, embeds in test_dataloader:\n",
    "        data = data.to(modelParameters[\"device\"])\n",
    "        sign_embed = model(data).to(\"cuda\")\n",
    "        sign_embed = sign_embed.to(dtype=torch.bfloat16)\n",
    "\n",
    "        # Normaliza ambos embeddings antes de calcular similitud\n",
    "        sign_embed = sign_embed.to(\"cuda\")\n",
    "        embeds = embeds.to(\"cuda\")\n",
    "        \n",
    "        similarity = torch.mean(torch.sum(sign_embed * embeds.T, dim=-1))  # ya que están normalizados\n",
    "        print(similarity)\n",
    "        \n",
    "        # print(mslm.generate(sign_embed, text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
