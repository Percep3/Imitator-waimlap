{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游붠 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/ramenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.5.1 with CUDA 1201 (you have 2.6.0+cu124)\n",
      "    Python  3.11.10 (you have 3.11.11)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游붠 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 * 2\n",
    "dtype = None\n",
    "load_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.17: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA GeForce GTX 1650. Num GPUs = 1. Max memory: 3.806 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener capa de embeddings\n",
    "embedding_layer = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del model # eliminar el modelo\n",
    "\n",
    "while True:\n",
    "    torch.cuda.empty_cache()\n",
    "    if gc.collect() == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_embed = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 128256, d_model: 3072\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = embedding_layer.weight.data.to(device_embed)  # Tensor de forma [vocab_size, d_model]\n",
    "vocab_size, d_model = all_embeddings.shape\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}, d_model: {d_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_token(embedding, all_embeddings):\n",
    "    embedding = embedding.to(device_embed)\n",
    "    if embedding.dim() > 1:\n",
    "        embedding = embedding.squeeze()\n",
    "\n",
    "    # Calcular similitud del coseno\n",
    "    similarities = F.cosine_similarity(embedding.unsqueeze(0), all_embeddings, dim=1)\n",
    "\n",
    "    # Encontrar el 칤ndice del token m치s similar\n",
    "    closest_token_id = torch.argmax(similarities).item()\n",
    "    return closest_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Token-to-Embedding-to-Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[128000,     71,   8083]])\n",
      "Embeddings: tensor([[[-1.1587e-04,  3.8528e-04, -1.9379e-03,  ...,  2.3937e-04,\n",
      "          -5.4550e-04,  8.8215e-05],\n",
      "         [-3.2715e-02,  8.1787e-03,  3.5095e-03,  ...,  1.6113e-02,\n",
      "          -3.4332e-04, -1.4526e-02],\n",
      "         [-2.1118e-02,  1.0681e-02, -2.4261e-03,  ..., -1.9165e-02,\n",
      "          -5.8594e-02, -1.4404e-02]]], device='cuda:0', dtype=torch.float16)\n",
      "Embeddings shape: torch.Size([1, 3, 3072])\n",
      "Token m치s cercano: <|begin_of_text|> (ID: 128000)\n",
      "Token m치s cercano: h (ID: 71)\n",
      "Token m치s cercano: ola (ID: 8083)\n"
     ]
    }
   ],
   "source": [
    "palabra = \"hola\"\n",
    "tokens = tokenizer(palabra, return_tensors=\"pt\")\n",
    "token_ids = tokens[\"input_ids\"]\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "embeddings = embedding_layer(token_ids.to(\"cuda\"))\n",
    "print(f\"Embeddings: {embeddings}\\nEmbeddings shape: {embeddings.shape}\")\n",
    "\n",
    "for emb in embeddings[0]:  # embeddings[0] porque es un batch de tama침o 1\n",
    "    closest_token_id = find_closest_token(emb, all_embeddings)\n",
    "    closest_token = tokenizer.decode([closest_token_id])\n",
    "    print(f\"Token m치s cercano: {closest_token} (ID: {closest_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imitator(nn.Module):\n",
    "    def __init__(self, input_size=1088, output_size=128256, d_model=2048):\n",
    "        self.linear = nn.Linear(input_size, 512)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=16, dim_feedforward=8192, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=32)\n",
    "        self.pe = PositionalEncoding(d_model=d_model)\n",
    "        self.linear2 = nn.Linear(d_model, output_size)\n",
    "    \n",
    "    def fordward(self, x):\n",
    "        # x -> [batch_size, T, input_size]\n",
    "        x = self.linear(x) \n",
    "        x = self.pe(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignDataLoader(Dataset):\n",
    "    def __init__(self, llama_tokenizer, llama_embed_layer, keypointReader, device=\"cpu\"):\n",
    "        self.llama_tokenizer = llama_tokenizer\n",
    "        self.keypointReader = keypointReader\n",
    "        self.llama_embed_layer = llama_embed_layer\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.keypointReader[idx]\n",
    "        input_ids = self.llama_tokenizer(label)[\"input_ids\"].to(self.device)\n",
    "        embeddings = self.llama_embed_layer(input_ids)\n",
    "        return data, embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keypointReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=100, log_interval=10, learning_rate=1e-4):\n",
    "    model.train()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    writer = SummaryWriter(\"imitator_report\")\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"epoch\", \"loss\"])\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Entrenando\", colour=\"green\"):\n",
    "        total_loss = 0\n",
    "        for data, embeddings in train_loader:\n",
    "            data = data.to(\"cuda\")\n",
    "            embeddings = embeddings.to(\"cuda\")\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, embeddings)\n",
    "            total_loss += loss\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            df.loc[len(df)] = [epoch, f\"{total_loss/len(train_loader):.4f}\"]\n",
    "            clear_output()\n",
    "            display(df)\n",
    "    \n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypointReader = ... # La Giorgio clase que lee los keypoints\n",
    "dataset = SignDataLoader(tokenizer, embedding_layer, keypointReader)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_size = 1088 # cantidad de puntos x 2\n",
    "output_size = vocab_size\n",
    "learning_rate = 2e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model\n",
    "model = Imitator(input_size=input_size, output_size=output_size, d_model=d_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, dataloader, epochs=100, log_interval=10, learning_rate=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
